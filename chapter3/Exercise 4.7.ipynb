{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from abc import ABCMeta, abstractmethod, abstractproperty\n",
    "from copy import copy\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonDistribution(object):\n",
    "    def __init__(self,ramda,random_state = random.randint(0,1000)):\n",
    "        self.ramda = ramda\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "        \n",
    "    def get_random(self):\n",
    "        randsum = self.rng.random()\n",
    "        \n",
    "        currentsum = 0\n",
    "        n = 0\n",
    "        while True:\n",
    "            currentsum += (self.ramda ** n) / np.math.factorial(n) * np.exp(-self.ramda)\n",
    "            if currentsum > randsum:\n",
    "                return n\n",
    "            n += 1\n",
    "    \n",
    "    def get_distribution(self,limit=10):\n",
    "        retprobs = []\n",
    "        for n in range(limit):\n",
    "            prob = (self.ramda ** n) / np.math.factorial(n) * np.exp(-self.ramda)\n",
    "            retprobs.append(prob)\n",
    "        return retprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiniteMDP(object):\n",
    "    def __init__(self,states,actions,rewards,dynamics):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "        self.dynamics = dynamics\n",
    "    \n",
    "    def simplify(self):\n",
    "        sim_dynamics = {}\n",
    "        for one_state in tqdm.tqdm(self.dynamics):\n",
    "            sim_dynamics[one_state] = {}\n",
    "            for one_action in self.dynamics[one_state]:\n",
    "                dynamic_dic = {}\n",
    "                prob_dic = {}\n",
    "                \n",
    "                sim_dynamics[one_state][one_action] = dynamic_dic\n",
    "                \n",
    "                for (next_state,reward),prob in self.dynamics[one_state][one_action].items():\n",
    "                    dynamic_dic.setdefault(next_state,0)\n",
    "                    dynamic_dic[next_state] += reward * prob\n",
    "                    prob_dic.setdefault(next_state,0)\n",
    "                    prob_dic[next_state] += prob\n",
    "                            \n",
    "                for next_state in list(dynamic_dic.keys()):\n",
    "                    avg_reward = dynamic_dic[next_state] / prob_dic[next_state]\n",
    "                    dynamic_dic[next_state,avg_reward] = prob_dic[next_state]\n",
    "                    del dynamic_dic[next_state]\n",
    "        return FiniteMDP(copy(self.states),copy(self.actions),copy(self.rewards),sim_dynamics)\n",
    "\n",
    "class MDPEnv(metaclass=ABCMeta):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_states(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_actions(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_rewards(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_dynamics(self):\n",
    "        pass\n",
    "    \n",
    "    def get_mdp(self):\n",
    "        states = self.get_states()\n",
    "        actions = self.get_actions()\n",
    "        rewards = self.get_rewards()\n",
    "        dynamics = self.get_dynamics()\n",
    "        return FiniteMDP(states,actions,rewards,dynamics)\n",
    "    \n",
    "class CarRentalEnv(MDPEnv):\n",
    "    def __init__(self,request_1=3,request_2=4,return_1=3,return_2=2,car_maxnumber=20,carmove_fee=2,max_carmove=5,rental_fee=10):\n",
    "        self.request_1_dis = PoissonDistribution(request_1).get_distribution()\n",
    "        self.request_2_dis = PoissonDistribution(request_2).get_distribution()\n",
    "        \n",
    "        self.return_1_dis = PoissonDistribution(return_1).get_distribution()\n",
    "        self.return_2_dis = PoissonDistribution(return_2).get_distribution()\n",
    "        \n",
    "        self.car_maxnumber = car_maxnumber\n",
    "        self.carmove_fee = carmove_fee\n",
    "        self.max_carmove = max_carmove\n",
    "        self.rental_fee = rental_fee\n",
    "    \n",
    "    def get_states(self):\n",
    "        return [i for i in range((self.car_maxnumber + 1) * (self.car_maxnumber + 1))]\n",
    "    \n",
    "    def get_actions(self):\n",
    "        return list(range(-self.max_carmove,self.max_carmove + 1))\n",
    "    \n",
    "    def get_rewards(self):\n",
    "        # 这个reward种类着实有点多啊，先不遍历\n",
    "        pass\n",
    "    \n",
    "    def get_state_dynamics(self,state,carmoved):\n",
    "        state2ab = lambda s:divmod(s,self.car_maxnumber + 1)\n",
    "        ab2state = lambda a,b: a * (self.car_maxnumber + 1) + b\n",
    "        \n",
    "        reward_movecar = -self.carmove_fee * carmoved\n",
    "        \n",
    "        reward_tostate_prob = {}\n",
    "        a_num,b_num = state2ab(state)\n",
    "        #assert(a_num <= self.car_maxnumber and b_num <= self.car_maxnumber)\n",
    "        for request_1,request_1_prob in enumerate(self.request_1_dis):\n",
    "            for return_1,return_1_prob in enumerate(self.return_1_dis):\n",
    "                for request_2,request_2_prob in enumerate(self.request_2_dis):\n",
    "                    for return_2,return_2_prob in enumerate(self.return_2_dis):\n",
    "                        reward_1 = min(request_1,a_num) * self.rental_fee\n",
    "                        reward_2 = min(request_2,b_num) * self.rental_fee\n",
    "                        \n",
    "                        remain_1 = a_num - min(request_1,a_num) + return_1\n",
    "                        remain_2 = b_num - min(request_2,b_num) + return_2\n",
    "                        remain_1 = min(remain_1,self.car_maxnumber)\n",
    "                        remain_2 = min(remain_2,self.car_maxnumber)\n",
    "                        \n",
    "                        assert(remain_1 >= 0 and remain_2 >= 0)\n",
    "                        \n",
    "                        nextstate = ab2state(remain_1,remain_2)\n",
    "                        total_reward = reward_movecar + reward_1 + reward_2\n",
    "                        \n",
    "                        reward_tostate_prob.setdefault((nextstate,total_reward),0)\n",
    "                        reward_tostate_prob[(nextstate,total_reward)] += request_1_prob * request_2_prob * return_1_prob * return_2_prob\n",
    "        return reward_tostate_prob\n",
    "        \n",
    "    def get_dynamics(self):\n",
    "        state2ab = lambda s:divmod(s,self.car_maxnumber + 1)\n",
    "        ab2state = lambda a,b: a * (self.car_maxnumber + 1) + b\n",
    "        \n",
    "        dynamics = {}\n",
    "        \n",
    "        for one_state in tqdm.tqdm(range((self.car_maxnumber + 1) * (self.car_maxnumber + 1))):\n",
    "            dynamics[one_state] = {}\n",
    "            a_num,b_num = state2ab(one_state)\n",
    "            for one_action in self.get_actions():\n",
    "                a2bnum = one_action\n",
    "                if a2bnum > a_num or - a2bnum > b_num:\n",
    "                    continue\n",
    "                \n",
    "                dynamics[one_state][one_action] = {}\n",
    "                \n",
    "                # a2bnum为正时为从a到b移动车辆，反之为从b到a\n",
    "                a_moved_num,b_moved_num = a_num - a2bnum,b_num + a2bnum\n",
    "                assert(a_moved_num >= 0 and b_moved_num >= 0)\n",
    "                to_state = ab2state(a_moved_num,b_moved_num)\n",
    "                \n",
    "                dynamics[one_state][one_action] = self.get_state_dynamics(to_state,np.abs(a2bnum))\n",
    "        return dynamics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "carRentalEnv = CarRentalEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [02:37<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "mdp = carRentalEnv.get_mdp()\n",
    "dynamics = mdp.dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [00:32<00:00, 13.41it/s]\n"
     ]
    }
   ],
   "source": [
    "mdp_simplify = mdp.simplify()\n",
    "dynamics_simplify = mdp_simplify.dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyIterationSolver(object):\n",
    "    def __init__(self,mdp,ramda=0.9):\n",
    "        self.mdp = mdp\n",
    "        self.dynamics = self.mdp.dynamics\n",
    "        self.states = self.mdp.states\n",
    "        \n",
    "        self.actions = self.mdp.actions\n",
    "        self.action2ind = dict(zip(self.actions,list(range(len(self.actions)))))\n",
    "        self.ind2action = dict(zip(list(range(len(self.actions))),self.actions))\n",
    "        \n",
    "        assert(0 in self.actions)\n",
    "        \n",
    "        self.Q_values = np.zeros([len(self.states),len(self.actions)],dtype=np.float)\n",
    "        self.strategy = np.zeros(len(self.states),dtype=np.int)\n",
    "        self.ramda = ramda\n",
    "        \n",
    "    def policy_evaluation_iter(self):\n",
    "        delta = 0\n",
    "        for one_state in self.states:\n",
    "            for one_action in self.dynamics[one_state]:\n",
    "                action_ind = self.action2ind[one_action]\n",
    "                q = self.Q_values[one_state][action_ind]\n",
    "                \n",
    "                new_q = 0\n",
    "                # TODO 看看这里有没有bug\n",
    "                for (next_state,reward),prob in self.dynamics[one_state][one_action].items():\n",
    "                    new_q += (\n",
    "                            prob * (reward + self.ramda * self.Q_values[next_state,self.action2ind[self.strategy[next_state]]])\n",
    "                        )\n",
    "                delta = max(delta,np.abs(q - new_q))\n",
    "                self.Q_values[one_state][action_ind] = new_q\n",
    "        return delta\n",
    "    \n",
    "    def policy_evaluation(self,eps=0.1,max_step=100):\n",
    "        for one_step in range(max_step):\n",
    "            delta = self.policy_evaluation_iter()\n",
    "            print(\"delta for step {}: {}\".format(one_step + 1,delta))\n",
    "            if delta < eps:\n",
    "                break\n",
    "    \n",
    "    def policy_improvement(self):\n",
    "        policy_stable = True\n",
    "        \n",
    "        for one_state in self.states:\n",
    "            old_action = self.strategy[one_state]\n",
    "            \n",
    "            new_action = None\n",
    "            max_q = -np.inf\n",
    "            for one_action in self.dynamics[one_state]:\n",
    "                action_ind = self.action2ind[one_action]\n",
    "                qsa = self.Q_values[one_state][action_ind]\n",
    "                if qsa > max_q:\n",
    "                    max_q = qsa\n",
    "                    new_action = one_action\n",
    "            assert(new_action is not None)\n",
    "            if new_action != old_action:\n",
    "                policy_stable = False\n",
    "            self.strategy[one_state] = new_action\n",
    "        return policy_stable\n",
    "    \n",
    "    def solve(self,steps=100):\n",
    "        current_step = 0\n",
    "        while current_step < steps:\n",
    "            current_step += 1\n",
    "            print(\"Evaluating,step {}\".format(current_step))\n",
    "            self.policy_evaluation()\n",
    "            policy_stable = self.policy_improvement()\n",
    "            print(\"Improved,step {}\".format(current_step))\n",
    "            if policy_stable:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pis = PolicyIterationSolver(mdp_simplify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating,step 1\n",
      "delta for step 1: 218.1057968975199\n",
      "delta for step 2: 156.62599029853484\n",
      "delta for step 3: 91.25370244457719\n",
      "delta for step 4: 63.63560638107518\n",
      "delta for step 5: 49.7508246166214\n",
      "delta for step 6: 38.10887805213747\n",
      "delta for step 7: 29.343617957687286\n",
      "delta for step 8: 22.945149327787817\n",
      "delta for step 9: 18.880768982070776\n",
      "delta for step 10: 15.601811185734618\n",
      "delta for step 11: 12.857391621745649\n",
      "delta for step 12: 10.569213509213284\n",
      "delta for step 13: 8.667883923962677\n",
      "delta for step 14: 7.093135923084162\n",
      "delta for step 15: 5.792969996137572\n",
      "delta for step 16: 4.722689644389391\n",
      "delta for step 17: 3.844049172027667\n",
      "delta for step 18: 3.1245051688426884\n",
      "delta for step 19: 2.5365344881808483\n",
      "delta for step 20: 2.0569996046215238\n",
      "delta for step 21: 1.6665585461769865\n",
      "delta for step 22: 1.3491234165542778\n",
      "delta for step 23: 1.0913719596189821\n",
      "delta for step 24: 0.8823143808916143\n",
      "delta for step 25: 0.7129149427040602\n",
      "delta for step 26: 0.5757656448821535\n",
      "delta for step 27: 0.4648078430619762\n",
      "delta for step 28: 0.37509688236201555\n",
      "delta for step 29: 0.30260457495029414\n",
      "delta for step 30: 0.24405445925162894\n",
      "delta for step 31: 0.19678510806278382\n",
      "delta for step 32: 0.15863720002209902\n",
      "delta for step 33: 0.12786056286080338\n",
      "delta for step 34: 0.10303789206608371\n",
      "delta for step 35: 0.08302231739196486\n",
      "Improved,step 1\n",
      "Evaluating,step 2\n",
      "delta for step 1: 50.560073503360286\n",
      "delta for step 2: 22.27494232648013\n",
      "delta for step 3: 1.615394376611448\n",
      "delta for step 4: 1.3247686847049636\n",
      "delta for step 5: 1.0878274825354879\n",
      "delta for step 6: 0.8786051091495324\n",
      "delta for step 7: 0.7067434364490168\n",
      "delta for step 8: 0.5678539163474738\n",
      "delta for step 9: 0.45606308743202817\n",
      "delta for step 10: 0.3662050844494047\n",
      "delta for step 11: 0.2940198736179127\n",
      "delta for step 12: 0.2360491172206025\n",
      "delta for step 13: 0.18950132496030392\n",
      "delta for step 14: 0.15212910895985488\n",
      "delta for step 15: 0.12212543855957847\n",
      "delta for step 16: 0.09803832258131706\n",
      "Improved,step 2\n",
      "Evaluating,step 3\n",
      "delta for step 1: 4.39288713731105\n",
      "delta for step 2: 3.245732518865907\n",
      "delta for step 3: 1.9094341402613964\n",
      "delta for step 4: 1.2557501162464177\n",
      "delta for step 5: 0.8130924874187713\n",
      "delta for step 6: 0.523747337829036\n",
      "delta for step 7: 0.3402175504749039\n",
      "delta for step 8: 0.23969469786271702\n",
      "delta for step 9: 0.1771476266718537\n",
      "delta for step 10: 0.13230797706330577\n",
      "delta for step 11: 0.10024527109675319\n",
      "delta for step 12: 0.0771589333582483\n",
      "Improved,step 3\n",
      "Evaluating,step 4\n",
      "delta for step 1: 0.34592194720801217\n",
      "delta for step 2: 0.18354099132125157\n",
      "delta for step 3: 0.09290327438088752\n",
      "Improved,step 4\n",
      "Evaluating,step 5\n",
      "delta for step 1: 0.06328806526914832\n",
      "Improved,step 5\n"
     ]
    }
   ],
   "source": [
    "pis.solve(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x122585090>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.asarray(pis.strategy).reshape(21,21)[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModCarRentalEnv(CarRentalEnv):\n",
    "    def __init__(self,a2bfree=1,second_parking_fee=4,second_parking_threshold=10):\n",
    "        super().__init__()\n",
    "        self.a2bfree = a2bfree\n",
    "        self.second_parking_fee = second_parking_fee\n",
    "        self.second_parking_threshold = second_parking_threshold\n",
    "    \n",
    "    def get_state_dynamics(self,state,carmoved):\n",
    "        state2ab = lambda s:divmod(s,self.car_maxnumber + 1)\n",
    "        ab2state = lambda a,b: a * (self.car_maxnumber + 1) + b\n",
    "        \n",
    "        reward_movecar = -self.carmove_fee * carmoved\n",
    "        # 特殊规则1 Jack‘s employee\n",
    "        if carmoved == 1:\n",
    "            reward_movecar = 0\n",
    "        \n",
    "        reward_tostate_prob = {}\n",
    "        a_num,b_num = state2ab(state)\n",
    "        #assert(a_num <= self.car_maxnumber and b_num <= self.car_maxnumber)\n",
    "        for request_1,request_1_prob in enumerate(self.request_1_dis):\n",
    "            for return_1,return_1_prob in enumerate(self.return_1_dis):\n",
    "                for request_2,request_2_prob in enumerate(self.request_2_dis):\n",
    "                    for return_2,return_2_prob in enumerate(self.return_2_dis):\n",
    "                        reward_1 = min(request_1,a_num) * self.rental_fee\n",
    "                        reward_2 = min(request_2,b_num) * self.rental_fee\n",
    "                        \n",
    "                        remain_1 = a_num - min(request_1,a_num) + return_1\n",
    "                        remain_2 = b_num - min(request_2,b_num) + return_2\n",
    "                        remain_1 = min(remain_1,self.car_maxnumber)\n",
    "                        remain_2 = min(remain_2,self.car_maxnumber)\n",
    "                        \n",
    "                        assert(remain_1 >= 0 and remain_2 >= 0)\n",
    "                        \n",
    "                        # 特殊规则2 second parking lot\n",
    "                        reward_parking = 0\n",
    "                        if remain_1 > self.second_parking_threshold:\n",
    "                            reward_parking -= self.second_parking_fee\n",
    "                        if remain_2 > self.second_parking_threshold:\n",
    "                            reward_parking -= self.second_parking_fee\n",
    "                        \n",
    "                        nextstate = ab2state(remain_1,remain_2)\n",
    "                        total_reward = reward_movecar + reward_1 + reward_2 + reward_parking\n",
    "                        \n",
    "                        reward_tostate_prob.setdefault((nextstate,total_reward),0)\n",
    "                        reward_tostate_prob[(nextstate,total_reward)] += request_1_prob * request_2_prob * return_1_prob * return_2_prob\n",
    "        return reward_tostate_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modCarRentalEnv = ModCarRentalEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [02:57<00:00,  2.48it/s]\n",
      "100%|██████████| 441/441 [00:29<00:00, 14.86it/s]\n"
     ]
    }
   ],
   "source": [
    "mod_mdp = modCarRentalEnv.get_mdp()\n",
    "mod_dynamics = mod_mdp.dynamics\n",
    "\n",
    "mod_mdp_simplify = mod_mdp.simplify()\n",
    "mod_dynamics_simplify = mod_mdp_simplify.dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating,step 1\n",
      "delta for step 1: 197.47122672499938\n",
      "delta for step 2: 144.34917829285243\n",
      "delta for step 3: 84.52877414119607\n",
      "delta for step 4: 61.724082688387824\n",
      "delta for step 5: 48.50339080539561\n",
      "delta for step 6: 37.19069812693567\n",
      "delta for step 7: 28.59892810079424\n",
      "delta for step 8: 22.308565754000256\n",
      "delta for step 9: 18.355091338239646\n",
      "delta for step 10: 15.116113205895488\n",
      "delta for step 11: 12.42031099180872\n",
      "delta for step 12: 10.18373232049521\n",
      "delta for step 13: 8.333236200870317\n",
      "delta for step 14: 6.806248840531964\n",
      "delta for step 15: 5.549508072344167\n",
      "delta for step 16: 4.517777842130442\n",
      "delta for step 17: 3.672747748723623\n",
      "delta for step 18: 2.9821012277599266\n",
      "delta for step 19: 2.418704128517959\n",
      "delta for step 20: 1.9598826563446323\n",
      "delta for step 21: 1.5867769589060572\n",
      "delta for step 22: 1.2837653539274356\n",
      "delta for step 23: 1.037956696355593\n",
      "delta for step 24: 0.8387479868870287\n",
      "delta for step 25: 0.6774431098858713\n",
      "delta for step 26: 0.546927510285343\n",
      "delta for step 27: 0.4413929805334078\n",
      "delta for step 28: 0.35610653630624256\n",
      "delta for step 29: 0.28721751372216886\n",
      "delta for step 30: 0.23159740373506565\n",
      "delta for step 31: 0.18670745109022846\n",
      "delta for step 32: 0.15048961085636847\n",
      "delta for step 33: 0.1212770244860053\n",
      "delta for step 34: 0.0977207180931714\n",
      "Improved,step 1\n",
      "Evaluating,step 2\n",
      "delta for step 1: 65.53645351659401\n",
      "delta for step 2: 33.920383051946544\n",
      "delta for step 3: 3.5067371669489944\n",
      "delta for step 4: 2.848245884364246\n",
      "delta for step 5: 2.324002739959724\n",
      "delta for step 6: 1.8681013554429455\n",
      "delta for step 7: 1.5058878643003482\n",
      "delta for step 8: 1.211547488548831\n",
      "delta for step 9: 0.9738912957189996\n",
      "delta for step 10: 0.7824909032281084\n",
      "delta for step 11: 0.6285394886672862\n",
      "delta for step 12: 0.5047972530267089\n",
      "delta for step 13: 0.4053771080666593\n",
      "delta for step 14: 0.325518014340787\n",
      "delta for step 15: 0.26138097458482434\n",
      "delta for step 16: 0.2098756293917745\n",
      "delta for step 17: 0.16851669103255063\n",
      "delta for step 18: 0.13530664966549466\n",
      "delta for step 19: 0.10864062361071092\n",
      "delta for step 20: 0.08722948157191013\n",
      "Improved,step 2\n",
      "Evaluating,step 3\n",
      "delta for step 1: 10.68356106046258\n",
      "delta for step 2: 6.4759203915640455\n",
      "delta for step 3: 2.9941958109161533\n",
      "delta for step 4: 1.6500615459910932\n",
      "delta for step 5: 0.9770114967908512\n",
      "delta for step 6: 0.6061411978430442\n",
      "delta for step 7: 0.3915579633090829\n",
      "delta for step 8: 0.2914115997172644\n",
      "delta for step 9: 0.21853065590653387\n",
      "delta for step 10: 0.16596338936653865\n",
      "delta for step 11: 0.12766455827545542\n",
      "delta for step 12: 0.10217161288289844\n",
      "delta for step 13: 0.08211456661547345\n",
      "Improved,step 3\n",
      "Evaluating,step 4\n",
      "delta for step 1: 0.4018290509529834\n",
      "delta for step 2: 0.18606567165306842\n",
      "delta for step 3: 0.08526847913037727\n",
      "Improved,step 4\n"
     ]
    }
   ],
   "source": [
    "mod_pis = PolicyIterationSolver(mod_mdp_simplify)\n",
    "mod_pis.solve(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f4b8ac90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(np.asarray(mod_pis.strategy).reshape(21,21)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
